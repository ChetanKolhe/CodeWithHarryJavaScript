Python Treading Tutorial
1965 : Gordon E. Moore
The number of transistors in a dense integrated circuit will continue to double approximately double every 2 years.

What concurrency: is the execution of multiple instruction sequence at the same time .

Order of Execution .
Share Resource .


Concurrency Types:
1. Parallel Programming . ( Best suitted by CPU intensive task )
	e.g
	String operations
	Search Algorithms
	Grpahic Processing
	Number Crunching
	Algorithms


2. Asynchronous Programming . ( Best suitted for IP bound task )
	Delegating to task some other thread or actore and continue doing other work .
	When subtask get completed it note back to main therad , this is generally called
	callback function .

	Database reads , wirtes .
	Web Service calls
	Copying , downloading , uploading data .


Python support both parallel and Asynchronous Programming natively .
threading 1.5 , multiprocessing 2.6+

concurrent.futures 3.2
asyncio 3.4



Process :
The execution context of a running program .
or running instace of computer program .


Thread : The smallest sequence of instruction that can be managed by operating system .


How to create a Thread

import threading

def do_somework(val):
    print("doing some work in thread")
	print("Eval : {}".format(val))
    return

val = "text"
t = threading.Thread(target=do_some_work, args=(val,))
t.start()
t.join()


class threading.Thread(group=None,
                       target=None,
					   name=None,
					   args=(),
					   kwargs={},
					   daemon=None
					   )

A boolean value indicating whether this thread is a daemon thread (True) or not (False).
This must be set before start() is called, otherwise RuntimeError is raised.
Its initial value is inherited from the creating thread;
the main thread is not a daemon thread and therefore all threads created in the main thread default to daemon = False.


Creating thread by using extending thread module .

class myThread(theading.Thread):
	def __init__(self):
		super().__init__()    # Thead.__init__(self)   same thing can also be called in that way

	def run(self):
		print("This is running thread")

my_feb_task = myThread(1)
my_feb_task.start()
my_feb_task.join()



Thread Lifecycle

New --> Ready --> Running -->Terminate
			\		/
			 \	   /
			 Blocked


Once thread had started we have little control over it .

The Scheduler :
 an operating system module that select next jobs to be admitted into the
 system and the next process to run .


Context Switch :
the process of saving and restoring the state of a thread or process .

Context switching using process to expensive rather than thread .
This is one of the reason parallel programing using thread over thread .
Parallel processing over processing .


Thread Interferene .
If resource share between thread , then most probably thread interferance will occure .
Same thing also called as race condition .
Due to that may be data corruption also occur .



In multithreading , it is best practice to share minimum resource .



Thread Synchronization

threading>Lock

	locked or unlocked

	lock.acquire()
	lock.release()

example
	lock = threading.Lock()
	lock.acquire()
	try:
		...access shared resource
	finally:
		lock.release()

using context manager (with) which is easy to manage acquizition and relasing locked

example
	lock = threading.Lock()

	with lock:
		...acess share resource .


acquire() also take addtional argument boolean .
which is used if lock is acquired then perform some other operation .

if lock.acquire(false):
	lock acquired, do stuff with lock
else:
	... could not acquire lock , do other stuff .


there is other similar method also present

if locke.locked():
	do other stuff
else:
	lock.acquire()


Catagory of lock.

		Renterent Lock : RLock()

lock = threading.Lock()
lock.acqure()
lock.acqurie()  # this call will block

lock = threading.RLock()
lock.acquire()
lock.acquire()  # this call won't block





Semaphore is another synchronization technique which manages internal counter .


semaphore = threading.Semaphore(4)
semaphore.acquire() # decrement the counter .
... access the shared resource .
semphore.release()  # increase the coutner .


in common termnology semaphore maintain the set of permit .

if relase() function get called multiple times it counter may increase more than 4  .

to solve this problem  BoundedSemaphore introduced .
num_permit = 3
bounded_semaphore = threading.BoundedSemaphore(num_permit)




Threding Event :
one thread signal the event , other thread simply wait thread .


event = threading.Event()

# client thead can wait for the flag to be set
event.wait()

# server thread can set or reset it
event.set()    # set the flage to true .
event.clear()  # reset the flag to false.

example
	import threading
	import time
	event = threading.Event()
	def consumer():
		print("Consumer waiting for supplier permission")
		event.wait()
		print("Consumer given a permission ")


	def supplier():
		print("Setting the event")
		event.set()

	thread_1 = threading.Thread(target=consumer, args=())
	thread_2 = threading.Thread(target=supplier, args=())
	thread_1.start()
	time.sleep(4)
	thread_2.start()
	thread_1.join()
	thread_2.join()




threding.Condition:
It  just combine the property of lock and event .

like locke , it have
acquire() and release() method

like event
wait(), notify() , notify_all()


Example

cond = threading.Condition()
# consumer one itme
cond.acquire()
while not an_time_is_availaible():
    condi.wait()
get_an_avaialable_itme()
cond.release()

# Produce one item
make_an_item_available()
cond.notify()
cond.release()



If we don't want to involve event , condition then use queue.

Inter thread communication using Queues

put() : Puts an item into the queue
get() : Removes an item from queue.
task_done(): Marks an itme that was gotten from the queue as completed / processed .
It is used for joining main thread .

join() : Block until all the itmes in the queue have been processed .


Example :
from threading import Thread
from queue import Queues

def producer(queue):
	for i in range(10):
		time = make_an_itemavailaible()
		queue.put(item)

def consumer(queue):
	while True:
		item = queue.get()

		# do something with the item
		queue.task_done()  # mark the item as done . I

 queue = Queue()
 t1 = Thread(target=producer, args=(queue))
 t2 = Thread(target=consumer, args=(queue))
 t1.start()
 t2.start()


 Global Interpreter Lock
 The lock that prevent multiple native thread from executing Python code at same time .

 Python threading is not thread , this most majority of people think .
 To prevent race condition or thread interferance .


 That allow to write python code easy .
 It improve the single core performance .

GIL Workarournds : GIL -less Python Interpretor
		-- Jython
		-- IronPython

	Python Multiprocessing


Multiprocessing :

Process don't share memory and resources with other Process .
But some exception to where process ask operyting system to share resource some singnal or calls .

Adv :
Side Steps GIL
Less need for synchronization .
Can be paused or terminated .
More resilent

Dis:
Higher memory foot print .
Expensive context swithch .

Multiprocessing API
It is design to similar to threading API

e.g
import multiprocessing
import time
def do_some_work(value):
    time.sleep(10)
    print(value)

if __name__ == '__main__':
    p1 = multiprocessing.Process(target=do_some_work, args=(12,), daemon=True)
    p1.start()
    p1.join()


Pickling : Is the process where python ojbect hierchy is converted into bytestream .
Unpickling : Is reverse operation .


class multiprocessing.Process(group=None,
							  target=None,
							  name=None,
							  args=(),
							  kwargs=(),
							  daemon=None)


Daemon Process:
is a child process that does not prevent its parent process from exiting .

Terminating Process :
Process is killable by operating system API .

is_alive()
terminate()

p.exitcode : this attribute is used for determineing exit code .

process.terminate()
shared resources my be put in an inconsistent state .
Finally clauses and exit handler will not be run.

ProcessPools : An easy way to execute fixed pool of process .

multiprocessing.Pool class .


multiprocessing.Pool( num_of_process ,    # by defautl number of core	
					  initilizer,         # initilizer function
					  initargs ,          # picklable not required 
					  maxtaxperchild ,    # by default it is none , meaning that worker process alive
					                        as long as pool alive .
											if value set , after executing number of times the worker process get killed 
											and new process used .
											This ensure that long running process periodically release the resources 


											

The most common use case of pool .

pool.map(function , iterable object )

Example :
import multiprocessing

def do_work(data):
    return data**2

def start_process():
    print("Starting process",multiprocessing.current_process().name)

if __name__ == "__main__":
    process_count = multiprocessing.cpu_count() -1
    process_pool = multiprocessing.Pool(processes=process_count,
    initializer=start_process,maxtasksperchild=1)

    input_list = list(range(10))
    output  = process_pool.map(do_work,input_list)
    print("Output", output)
    process_pool.close()   # No more task submitted to pool .
    process_pool.join()   # wait for worker process to exit .

	
	There are async version of map funtion also availaible .
	
	join() method should be called after termination of pool or close() 
	


Pool.map_async(func, iterable , chunks , callback , ) return AsyncResult 
AsyncResult.get(timeout)  # Return a result when available
AsyncResult.successful

Similar function which take only one argument 
Pool.apply()
Poll.apply_async()

Inter Process Communication 
By default process don't share resources to each other .
If process want to share resources between two process need to use os supported communication channel.
if they want to exchange data between two channal.

Pipe, Queue.

Multiprocessing.Pipe : Represent two end connetion of the pipe

Pipe() : It will return two connection object . conn1 will send data to conn2
Pipe(True) : Connection is bidirection .  

conn.recv() : it will wait for data .

Pipe generally cause data corruption it to connection try to send data in one time .
For this Queue is more modern or secure way for inter process connection .

It also impliment all standard call which impliment in normal queue call .

threading.Queue : qsize , put , get , empty , full , task_done , join,
multiprocessing.Queue : qsize , put ,get ,empty , full


There also other queue which also impliment task_done , join 
multiprocessing.JoinableQueue 
										























